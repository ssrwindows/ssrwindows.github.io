<!DOCTYPE html>
<html xml:lang="zh-CN" lang="zh-CN">

<head>
        <link rel="canonical" href="https://ssrwindows.github.io/news/article-41849.htm" />
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <title>pytorch定义新的自动求导函数</title>
        <meta name="description" content="在pytorch中想自定义求导函数，通过实现torch.autograd.Function并重写forward和backward函数，来定义自己的自动求导运算。参考官网上的demo：传送门  直接上代" />
        <link rel="icon" href="/assets/website/img/ssrwindows/favicon.ico" type="image/x-icon"/>

    <meta name="author" content="SSR Windows免费节点订阅站">
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://ssrwindows.github.io/news/article-41849.htm" />
    <meta property="og:site_name" content="SSR Windows免费节点订阅站" />
    <meta property="og:title" content="pytorch定义新的自动求导函数" />
    <meta property="og:image" content="https://ssrwindows.github.io/uploads/20240730/0846b1632e016e6b5181691903a0c154.webp" />
        <meta property="og:release_date" content="2025-01-17T09:30:14" />
    <meta property="og:updated_time" content="2025-01-17T09:30:14" />
        <meta property="og:description" content="在pytorch中想自定义求导函数，通过实现torch.autograd.Function并重写forward和backward函数，来定义自己的自动求导运算。参考官网上的demo：传送门  直接上代" />
    
    <meta name="applicable-device" content="pc,mobile" />
    <meta name="renderer" content="webkit" />
    <meta name="force-rendering" content="webkit" />
    <meta http-equiv="Cache-Control" content="no-transform" />
    <meta name="robots" content="max-image-preview:large" />
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="pytorch定义新的自动求导函数">
    <meta name="format-detection" content="telephone=no">

    <link rel="dns-prefetch" href="https:/www.googletagmanager.com">
    <link rel="dns-prefetch" href="https://www.googleadservices.com">
    <link rel="dns-prefetch" href="https://www.google-analytics.com">
    <link rel="dns-prefetch" href="https://pagead2.googlesyndication.com">
    <link rel="dns-prefetch" href="https://cm.g.doubleclick.net">
    <link rel="dns-prefetch" href="https://fonts.googleapis.com">

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">
    <!-- Vendor CSS Files -->
    <link href="/assets/website/js/frontend/ssrwindows/aos/aos.css" rel="stylesheet">
    <link href="/assets/website/js/frontend/ssrwindows/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="/assets/website/js/frontend/ssrwindows/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
    <link href="/assets/website/js/frontend/ssrwindows/boxicons/css/boxicons.min.css" rel="stylesheet">
    <link href="/assets/website/js/frontend/ssrwindows/glightbox/css/glightbox.min.css" rel="stylesheet">
    <link href="/assets/website/js/frontend/ssrwindows/swiper/swiper-bundle.min.css" rel="stylesheet">
    <!-- Template Main CSS File -->
    <link href="/assets/website/css/ssrwindows/style.css" rel="stylesheet">
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RSKEBF5GLS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-RSKEBF5GLS');
</script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3332997411212854"
     crossorigin="anonymous"></script>
</head>

<body data-page="detail">
        <!-- ======= Header ======= -->
    <header id="header" class="fixed-top  header-transparent ">
        <div class="container d-flex align-items-center justify-content-between">
            <div class="logo">
                <a href="/">
                                <span>SSR Windows</span>
                                </a>
            </div>
            <nav id="navbar" class="navbar">
                <ul>
                                        <li><a class="nav-link" href="/">首页</a></li>
                                        <li><a class="nav-link" href="/free-nodes/">免费节点</a></li>
                                        <li><a class="nav-link" href="/paid-subscribe/">推荐机场</a></li>
                                        <li><a class="nav-link" href="/client.htm">客户端</a></li>
                                        <li><a class="nav-link" href="/news/">新闻资讯</a></li>
                                    </ul>
                <i class="bi bi-list mobile-nav-toggle"></i>
            </nav><!-- .navbar -->
        </div>
    </header><!-- End Header -->
    <main id="main">
        <!-- ======= Breadcrumbs Section ======= -->
        <section class="breadcrumbs" style="margin-top: 5rem;">
            <div class="container">
                <div class="d-flex justify-content-between align-items-center">
                    <h1>pytorch定义新的自动求导函数</h1>
                    <ol>
                        <li><a href="/">首页</a></li>
                        <li><a href="/news/">新闻资讯</a></li>
                        <li>正文</li>
                    </ol>
                </div>
            </div>
        </section><!-- End Breadcrumbs Section -->
        <!-- ======= Details Section ======= -->
        <section id="details" class="details">
            <div class="container">
                <div class="row">
                    <div class="col-md-9">
                                        <input type="hidden" id="share-website-info" data-name="" data-url="">
                  				  				  				<div id="content_views" class="markdown_views prism-atom-one-dark"> <ol> <li>在pytorch中想自定义求导函数，通过实现torch.autograd.Function并重写forward和backward函数，来定义自己的自动求导运算。参考官网上的demo：<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html"  rel="nofollow">传送门</a> </li> <li>直接上代码，定义一个ReLu来实现自动求导</li> </ol> <pre><code class="prism language-python"><span class="token keyword">import</span> torch   <span class="token keyword">class</span> <span class="token class-name">MyRelu</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>Function<span class="token punctuation">)</span><span class="token punctuation">:</span>     @<span class="token builtin">staticmethod</span>     <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>ctx<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token comment"># 我们使用ctx上下文对象来缓存，以便在反向传播中使用，ctx存储时候只能存tensor</span>         <span class="token comment"># 在正向传播中，我们接收一个上下文对象ctx和一个包含输入的张量input；</span>         <span class="token comment"># 我们必须返回一个包含输出的张量，</span>         <span class="token comment"># input.clamp(min = 0)表示讲输入中所有值范围规定到0到正无穷，如input=[-1,-2,3]则被转换成input=[0,0,3]</span>         ctx<span class="token punctuation">.</span>save_for_backward<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>                  <span class="token comment"># 返回几个值，backward接受参数则包含ctx和这几个值</span>         <span class="token keyword">return</span> <span class="token builtin">input</span><span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token builtin">min</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>      @<span class="token builtin">staticmethod</span>     <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>ctx<span class="token punctuation">,</span> grad_output<span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token comment"># 把ctx中存储的input张量读取出来</span>         <span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token operator">=</span> ctx<span class="token punctuation">.</span>saved_tensors                  <span class="token comment"># grad_output存放反向传播过程中的梯度</span>         grad_input <span class="token operator">=</span> grad_output<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>                  <span class="token comment"># 这儿就是ReLu的规则，表示原始数据小于0，则relu为0，因此对应索引的梯度都置为0</span>         grad_input<span class="token punctuation">[</span><span class="token builtin">input</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>         <span class="token keyword">return</span> grad_input </code></pre> <ol start="3"> <li>进行输入数据并测试</li> </ol> <pre><code class="prism language-python">dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">float</span> device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span> <span class="token comment"># 使用torch的generator定义随机数，注意产生的是cpu随机数还是gpu随机数</span> generator<span class="token operator">=</span>torch<span class="token punctuation">.</span>Generator<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>  <span class="token comment"># N是Batch, H is hidden dimension，</span> <span class="token comment"># D_in is input dimension;D_out is output dimension.</span> N<span class="token punctuation">,</span> D_in<span class="token punctuation">,</span> H<span class="token punctuation">,</span> D_out <span class="token operator">=</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">10</span>  x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>N<span class="token punctuation">,</span> D_in<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span>generator<span class="token operator">=</span>generator<span class="token punctuation">)</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>N<span class="token punctuation">,</span> D_out<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> generator<span class="token operator">=</span>generator<span class="token punctuation">)</span>  w1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>D_in<span class="token punctuation">,</span> H<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>generator<span class="token punctuation">)</span> w2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>H<span class="token punctuation">,</span> D_out<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>generator<span class="token punctuation">)</span>  learning_rate <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     relu <span class="token operator">=</span> MyRelu<span class="token punctuation">.</span><span class="token builtin">apply</span>     <span class="token comment"># 使用函数传入参数运算 </span>     y_pred <span class="token operator">=</span> relu<span class="token punctuation">(</span>x<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mm<span class="token punctuation">(</span>w2<span class="token punctuation">)</span> 	<span class="token comment"># 计算损失</span>     loss <span class="token operator">=</span> <span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">if</span> t <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">99</span><span class="token punctuation">:</span>         <span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment"># 传播</span>     loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         w1 <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> w1<span class="token punctuation">.</span>grad         w2 <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> w2<span class="token punctuation">.</span>grad        	         w1<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>         w2<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span> </code></pre> <ol start="4"> <li>暂时先做这些测试，如有问题，恳请指正</li> </ol> </div> 			                <div class="clearfix"></div>
                <div class="col-md-12 mt-5">
                                        <p>上一个：<a href="/news/article-41351.htm">动物园兽医院电话（兽医院和动物医院电话号码）</a></p>
                                        <p>下一个：<a href="/news/article-41850.htm">养猫咪打针多少钱（养猫咪打针多少钱一次）</a></p>
                                    </div>
                                    </div>
                    <div class="col-md-3">
                        <div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">热门文章</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2"><a href="/news/article-36039.htm" title="成都宠物领养平台公众号是什么（成都宠物领养吧贴吧）">成都宠物领养平台公众号是什么（成都宠物领养吧贴吧）</a></li>
                        <li class="py-2"><a href="/news/article-59641.htm" title="宠物粮市场前景怎么样知乎视频大全（宠物粮进货平台）">宠物粮市场前景怎么样知乎视频大全（宠物粮进货平台）</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-2-10-clash-v2ray-ss-ssr.htm" title="2月10日|SSR/Clash/V2ray/Shadowrocket每天更新21.6M/S免费节点订阅链接，付费节点订阅推荐">2月10日|SSR/Clash/V2ray/Shadowrocket每天更新21.6M/S免费节点订阅链接，付费节点订阅推荐</a></li>
                        <li class="py-2"><a href="/news/article-49280.htm" title="学宠物美容有前途吗女生多少岁（学宠物美容有前途吗女生多少岁可以学）">学宠物美容有前途吗女生多少岁（学宠物美容有前途吗女生多少岁可以学）</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-1-27-node-share.htm" title="1月27日|Clash/Shadowrocket/SSR/V2ray每天更新18M/S免费节点订阅链接，付费节点订阅推荐">1月27日|Clash/Shadowrocket/SSR/V2ray每天更新18M/S免费节点订阅链接，付费节点订阅推荐</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-2-3-clash-v2ray-ss-ssr.htm" title="2月3日|SSR/Clash/V2ray/Shadowrocket每天更新19.3M/S免费节点订阅链接，付费节点订阅推荐">2月3日|SSR/Clash/V2ray/Shadowrocket每天更新19.3M/S免费节点订阅链接，付费节点订阅推荐</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-2-23-free-node-subscribe-links.htm" title="2月23日|Clash/SSR/V2ray/Shadowrocket每天更新20.3M/S免费节点订阅链接，付费节点订阅推荐">2月23日|Clash/SSR/V2ray/Shadowrocket每天更新20.3M/S免费节点订阅链接，付费节点订阅推荐</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-1-24-free-ssr-node.htm" title="1月24日|V2ray/Shadowrocket/SSR/Clash每天更新20.1M/S免费节点订阅链接，付费节点订阅推荐">1月24日|V2ray/Shadowrocket/SSR/Clash每天更新20.1M/S免费节点订阅链接，付费节点订阅推荐</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-1-6-free-ssr-node.htm" title="1月6日|V2ray/Shadowrocket/SSR/Clash每天更新19M/S免费节点订阅链接，付费节点订阅推荐">1月6日|V2ray/Shadowrocket/SSR/Clash每天更新19M/S免费节点订阅链接，付费节点订阅推荐</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-1-9-node-share-links.htm" title="1月9日|V2ray/Clash/Shadowrocket/SSR每天更新21.8M/S免费节点订阅链接，付费节点订阅推荐">1月9日|V2ray/Clash/Shadowrocket/SSR每天更新21.8M/S免费节点订阅链接，付费节点订阅推荐</a></li>
                    </ul>
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">归纳</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">12</span> <a href="/date/2025-03/" title="2025-03 归档">2025-03</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">84</span> <a href="/date/2025-02/" title="2025-02 归档">2025-02</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">84</span> <a href="/date/2025-01/" title="2025-01 归档">2025-01</a></h4>
            </li>
                    </ul>
    </div>
</div>

                    </div>
                </div>
            </div>
        </section><!-- End Details Section -->
    </main><!-- End #main -->
    <!-- ======= Footer ======= -->
<footer id="footer">
    <div class="container py-4">
        <div class="copyright">
                    <p>
                        <a href="/">首页</a> | 
                        <a href="/free-node/">免费节点</a> | 
                        <a href="/news/">新闻资讯</a> |
                        <a href="/about-us.htm">关于我们</a> |
                        <a href="/disclaimer.htm">免责申明</a> |
                        <a href="/privacy.htm">隐私申明</a> |
                        <a href="/sitemap.xml">网站地图</a>
                    </p>
            <a href="/">SSR Windows免费节点订阅站</a> 版权所有 Powered by WordPress
        </div>
    </div>
</footer><!-- End Footer -->
<a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>
<!-- Vendor JS Files -->
<script src="/assets/website/js/frontend/ssrwindows/jquery-3.5.1.min.js"></script>
<script src="/assets/website/js/frontend/ssrwindows/aos/aos.js"></script>
<script src="/assets/website/js/frontend/ssrwindows/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="/assets/website/js/frontend/ssrwindows/php-email-form/validate.js"></script>
<script src="/assets/website/js/frontend/ssrwindows/swiper/swiper-bundle.min.js"></script>
<!-- Template Main JS File -->
<script src="/assets/website/js/frontend/ssrwindows/main.js"></script>
<script src="https://www.freeclashnode.com/assets/js/frontend/invite-url.js"></script>
<script src="/assets/website/js/frontend/G.js"></script>
</body>

</html>